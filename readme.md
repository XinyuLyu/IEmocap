## ACL_Entire
Our contribution includes:
1. A high-efficiency multimodal network that extracts the word-level textual and acoustic features only rely on multi-level attention mechanism and without using any convolutional neural networks and recurrent neural networks.
2. A hybrid architecture that combines the feature extraction module and fusion module into a single network, which uses two independent fusion factors to learn the across-modality associations in each attention layer during feature extraction.
3. An end-to-end modeling strategy that synchronizes feature representation and modality fusion, and extremely facilitates model training.  
